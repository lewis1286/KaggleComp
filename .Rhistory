na.remove <- apply(training.features,1,function(x){sum(is.na(x)) > .25*pred})
summary(na.remove)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) > .35*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) > .30*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) > .35*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) > 0*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) > .1*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) > .15*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) > .25*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) < .25*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) < .4*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) < .35*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) < .30*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) < .35*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) < .25*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) < .28*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) < .30*pred})
summary(na.count)
na.count <- apply(training.features,1,function(x){sum(is.na(x)) < .29*pred})
summary(na.count)
t.subset = training.features[na.count,]
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(leaderboard.features, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- training.features[,!col.has.na]
v_feat <- validation.features[,!col.has.na]
l_feat <- leaderboard.features[,!col.has.na]
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.only.na <- apply(leaderboard.features, 2, function(x){sum(is.na(x)) == nrow(leaderboard.features)}) # logical of which columns are NA
t_feat <- training.features[,!col.has..only.na]
v_feat <- validation.features[,!col.has.only.na]
l_feat <- leaderboard.features[,!col.has.only.na]
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.only.na <- apply(leaderboard.features, 2, function(x){sum(is.na(x)) == nrow(leaderboard.features)}) # logical of which columns are NA
t_feat <- training.features[,!col.has.only.na]
v_feat <- validation.features[,!col.has.only.na]
l_feat <- leaderboard.features[,!col.has.only.na]
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < .29*pred})
summary(na.count)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < .5*pred})
summary(na.count)
View(training.target)
pred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < .5*pred})
summary(na.count)
t.subset = training.features[,na.count]
ratio = .5
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
summary(na.count)
ratio = .5
npred = ncol(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
summary(na.count)
seq(.2,.8,.1)
rm(list=ls())
require(xgboost)
require(boot)
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
rm(list=ls())
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
train.frame <- data.frame(train.target, train.predictors)
train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
require(xgboost)
require(boot)
# get rid of subject id while retaining ordering
train.target<-train.target$ALSFRS_slope
train.predictors<-train.predictors[,-1]
test.data <- v_feat[,-1] #l_feat[,-1]  # use l_feat[,-1] when you want to build a prediction for submission.
parameters = list(max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear")
bst <- xgboost(data = as.matrix(train.predictors), params = parameters)
bst <- xgboost(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear")
parameters = list(max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear")
# bst <- xgboost(data = as.matrix(train.predictors), params = parameters)
bst <- xgboost(data = as.matrix(train.predictors), label = train.target, params = parameters)
parameters = list(max.depth = 3, eta = .8, nthread = 2, nrounds = 2, objective = "reg:linear")
# bst <- xgboost(data = as.matrix(train.predictors), params = parameters)
bst <- xgboost(data = as.matrix(train.predictors), label = train.target, params = parameters)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear")
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
summary(bst)
names(bst)
rm(list=ls())
require(xgboost)
require(boot)
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
for (i in seq(.2,.8, .1)){
ratio = i
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
train.frame <- data.frame(train.target, train.predictors)
train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# Train using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
}
for (i in seq(.2,.8, .1)){
ratio = i
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# Train using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
}
for (i in seq(.2,.8, .1)){
ratio = i
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# Train using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
}
rm(list=ls())
require(xgboost)
require(boot)
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
for (i in seq(.2,.8, .1)){
ratio = i
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# Train using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
}
View(training.target)
dim(as.matrix(train.predictors))
dim(train.target)
View(train.predictors)
for (i in seq(.2,.8, .1)){
ratio = i
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(train.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
train.predictors <- train.predictors[-1]
train.target <- train.target[-1]
# Train using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
}
for (i in seq(.2,.8, .1)){
ratio = i
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(train.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# Train using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
}
rm(list=ls())
require(xgboost)
require(boot)
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
for (i in seq(.2,.8, .1)){
# remove predictors with more than <ratio> na's
ratio = i
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for remaining data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(train.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# remove subject id's
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# CV using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
}
for (i in seq(.2,.8, .1)){
# remove predictors with more than <ratio> na's
ratio = i
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for remaining data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# remove subject id's
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# CV using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
}
summary(bst)
bst$test.rmse.mean
bst$test.rmse.mean[1]
cv.test.error.mean = NULL
for (i in seq(.2,.8, .1)){
# remove predictors with more than <ratio> na's
ratio = i
npred = nrow(training.features)
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for remaining data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# remove subject id's
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# CV using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
cv.test.error.mean <- c(cv.test.error.mean, bst$test.rmse.mean[1])
}
plot(cv.test.error.mean)
summary(bst)
bst
npred = nrow(training.features)
cv.test.error.mean = NULL
ratio.range = seq(.2,.8,.05)
for (ratio in ratio.range){
# remove predictors with more than <ratio> na's
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for remaining data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# remove subject id's
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# CV using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
cv.test.error.mean <- c(cv.test.error.mean, bst$test.rmse.mean[1])
}
plot(ratio.range, cv.test.error.mean)
npred = nrow(training.features)
cv.test.error.mean = NULL
ratio.range = seq(.2,.8,.01)
for (ratio in ratio.range){
# remove predictors with more than <ratio> na's
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for remaining data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# remove subject id's
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# CV using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
cv.test.error.mean <- c(cv.test.error.mean, bst$test.rmse.mean[1])
}
plot(ratio.range, cv.test.error.mean)
npred = nrow(training.features)
cv.test.error.mean = NULL
ratio.range = seq(.2,.8,.1)
for (ratio in ratio.range){
# remove predictors with more than <ratio> na's
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for remaining data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# remove subject id's
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# CV using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 2, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
cv.test.error.mean <- c(cv.test.error.mean, bst$test.rmse.mean[1])
}
plot(ratio.range, cv.test.error.mean)
npred = nrow(training.features)
cv.test.error.mean = NULL
ratio.range = seq(.2,.8,.1)
for (ratio in ratio.range){
# remove predictors with more than <ratio> na's
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for remaining data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# remove subject id's
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# CV using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = 1, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
cv.test.error.mean <- c(cv.test.error.mean, bst$test.rmse.mean[1])
}
plot(ratio.range, cv.test.error.mean)
npred = nrow(training.features)
cv.test.error.mean = NULL
ratio.range = seq(.2,.8,.1)
for (ratio in ratio.range){
# remove predictors with more than <ratio> na's
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for remaining data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# remove subject id's
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# CV using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 2, objective = "reg:linear", nfold = 10)
cv.test.error.mean <- c(cv.test.error.mean, bst$test.rmse.mean[1])
}
plot(ratio.range, cv.test.error.mean)
npred = nrow(training.features)
cv.test.error.mean = NULL
ratio.range = seq(.2,.8,.1)
for (ratio in ratio.range){
# remove predictors with more than <ratio> na's
na.count <- apply(training.features,2,function(x){sum(is.na(x)) < ratio*npred})
t_feat = training.features[,na.count]
v_feat = validation.features[,na.count]
l_feat = leaderboard.features[,na.count]
# set NA's to medians for remaining data
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(l_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
# train.frame <- data.frame(train.target, train.predictors)
# train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
# remove subject id's
train.predictors <- train.predictors[,-1]
train.target <- train.target[,-1]
# CV using XGBoost (I have no clue what these settings are)
bst <- xgb.cv(data = as.matrix(train.predictors), label = train.target, max.depth = 3, eta = .8, nthread = 2, nround = 4, objective = "reg:linear", nfold = 10)
cv.test.error.mean <- c(cv.test.error.mean, bst$test.rmse.mean[1])
}
plot(ratio.range, cv.test.error.mean)
