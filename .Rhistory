for (r in seq(1:5)){
beta.hat <- coef(regfit.train, id=r)[2:r + 1]
# print(beta.hat)
beta.subset <- beta[names(beta.hat)]
# print(beta.subset)
val[r] <- sqrt(sum((beta.hat - beta.subset)^2))
}
plot(seq(1:20), val)
val
val = rep(0,20)
for (r in seq(1:20)){
beta.hat <- coef(regfit.train, id=r)[2:r + 1]
# print(beta.hat)
beta.subset <- beta[names(beta.hat)]
# print(beta.subset)
val[r] <- sqrt(sum((beta.hat - beta.subset)^2))
}
plot(seq(1:20), val)
val
val[15:16]
val = rep(0,20)
for (r in seq(1:20)){
beta.hat <- coef(regfit.train, id=r)[2:r + 1]
# print(beta.hat)
beta.subset <- beta[names(beta.hat)]
# print(beta.subset)
if(r == 1){
beta.hat <- beta.hat[2]
beta.subset <- beta.subset[2]
}
val[r] <- sqrt(sum((beta.hat - beta.subset)^2))
}
plot(seq(1:20), val)
train.mat <- model.matrix(Y~.,data = train.df, nmax = ncol(train.df) -1)
test.mat <- model.matrix(Y~., data = test.df)
# no predict function for regsubsets.  We predict ourselves, using the best subset generated
# on the training set (regfit.train)
val.errors = rep(NA, 20)
for(i in 1:20){
coefi <- coef(regfit.train, id=i) # pulls out the coefficients of the 'i' best predictors
pred <- test.mat[,names(coefi)] %*% coefi
val.errors[i] = mean((test.df$Y - pred)^2)
}
plot(val.errors, xlab = "p", ylab = "MSE test")
title(paste("test MSE, min MSE when p = ", which.min(val.errors)))
points(which.min(val.errors),val.errors[which.min(val.errors)],
col = "red", cex = 2, pch = 20)
which.min(val.errors)
# Change this to your data directory
data.dir <- "~/Dropbox/classes/STATs 202 data mining and analysis/ALS-kaggle-comp/KaggleComp/"
setwd(data.dir)
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
rm(list=ls())
# Change this to your data directory
data.dir <- "~/Dropbox/classes/STATs 202 data mining and analysis/ALS-kaggle-comp/KaggleComp/"
setwd(data.dir)
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
is.na(validation.target)
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
library(glmnet)
#massage data for the use of glmnet (needs matrix)
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
colnames(train.frame)[1] <- "ALSFRS_slope"
# train.frame[1:3,1:3]
x = model.matrix(ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization (alpha=1)
grid = 10^seq(10,-2, length=100)
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
# plot(lasso.mod) plotting doesn't work; too sparse
#perform cross validation
set.seed(1)
cv.out <- cv.glmnet(x,y,alpha=1)
plot(cv.out) # this takes about 3 minutes
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
rm(list=ls())
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
?rowSums
colSums(is.na(v_feat))
df <- v_feat[colssu]
df <- v_feat[colSums(is.na(v_feat)) < 1,]
dim(df)
dim(v_feat)
View(df)
library(glmnet)
#massage data for the use of glmnet (needs matrix)
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
colnames(train.frame)[1] <- "ALSFRS_slope"
# train.frame[1:3,1:3]
x = model.matrix(ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization (alpha=1)
grid = 10^seq(10,-2, length=100)
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
# plot(lasso.mod) plotting doesn't work; too sparse
#perform cross validation
set.seed(1)
cv.out <- cv.glmnet(x,y,alpha=1)
plot(cv.out) # this takes about 3 minutes
cv.out$lambda.min
bestlam <- cv.out$lambda.min
# build a test matrix to predict on:
#---------------------------------------------------------------
# something wrong with v_feat, its still got n'as.  maybe some columns
# are only na?  can I just remove these colums, or should I go back and make
# training and test datasets out of training.  ?  Recall validation is closer
# to what the actual test dataset will look like.
#----------------------------------------------------------------
test.frame <- data.frame(validation.target$ALSFRS_slope, v_feat)
colnames(test.frame)[1] <- "ALSFRS_slope"
x.test = model.matrix(ALSFRS_slope~., test.frame)[,-1]
y.test = test.frame$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
View(leaderboard.features)
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
View(leaderboard.features)
View(l_feat)
View(v_feat)
summary(l_feat$first.date.svc_normal)
is.na(v_feat$first.date.svc_normal)
summary(is.na(v_feat$first.date.svc_normal))
?complete.cases
dim(complete.cases(v_feat))
dim(v_feat[,complete.cases(v_feat)])
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
dim(v_feat[,complete.cases(v_feat)])
dim(t_feat[,complete.cases(t_feat)])
df = v_feat(na.omit)
df = v_feat[na.omit]
df = v_feat[,na.omit]
dim(t_feat[,complete.cases(t_feat)])
dim(v_feat[,complete.cases(v_feat)])
dim(l_feat[,complete.cases(l_feat)])
l_feat[,complete.cases(l_feat)]
col.has.na <- apply(v_feat, 2, function(x){any(is.na(x))})
sum(col.has.na)
names(col.has.na)
dim(col.has.na)
v_feat.filtered <- v_feat[,!col.has.na]
dim(v_feat.filtered)
dim(v_feat)
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(v_feat, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- t_feat[,!col.has.na]
v_feat <- v_feat[,!col.has.na]
l_feat <- l_feat[,!col.has.na]
?merge
dim(t_feat)
dim(v_feat)
df <- merge(t_feat, v_feat)
dim(df)
library(glmnet)
#massage data for the use of glmnet (needs matrix)
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
colnames(train.frame)[1] <- "ALSFRS_slope"
# train.frame[1:3,1:3]
x = model.matrix(ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization (alpha=1)
grid = 10^seq(10,-2, length=100)
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
# plot(lasso.mod) plotting doesn't work; too sparse
#perform cross validation
set.seed(1)
cv.out <- cv.glmnet(x,y,alpha=1)
plot(cv.out) # this takes about 3 minutes
cv.out$lambda.min
lasso.model <- glmnet(x , y, alpha=1, lambda = bestlam)
lasso.mod <- glmnet(x , y, alpha=1, lambda = bestlam)
test <- model.matrix(l_feat)
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = test)
ALSFRS_slope <- rep(0, dim(l_feat)[1])
l_feat <- data.frame(ALSFRS_slope, l_feat)
x.test <- model.matrix(l_feat$ALSFRS_slope~.,l_feat)[,-1]
y.test <- l_feat$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = test)
ALSFRS_slope <- rep(0, dim(l_feat)[1])
l_feat <- data.frame(ALSFRS_slope, l_feat)
x.test <- model.matrix(l_feat$ALSFRS_slope~.,l_feat)[,-1]
y.test <- l_feat$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
dim(l_feat)
dim(t_feat)
dim(v_feat)
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(l_feat, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- t_feat[,!col.has.na]
v_feat <- v_feat[,!col.has.na]
l_feat <- l_feat[,!col.has.na]
# for now, training on t_feat.  Later, lets merge t_feat and v_feat for training
dim(v_feat)
dim(t_feat)
dim(l_feat)
#massage data for the use of glmnet (needs matrix)
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
colnames(train.frame)[1] <- "ALSFRS_slope"
# train.frame[1:3,1:3]
x = model.matrix(ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization (alpha=1)
grid = 10^seq(10,-2, length=10)
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
# plot(lasso.mod) plotting doesn't work; too sparse
#perform cross validation on best choice of lambda
set.seed(1)
cv.out <- cv.glmnet(x,y,alpha=1)
plot(cv.out) # this takes about 3 minutes
bestlam <- cv.out$lambda.min
lasso.mod <- glmnet(x , y, alpha=1, lambda = bestlam)
ALSFRS_slope <- rep(0, dim(l_feat)[1])
l_feat <- data.frame(ALSFRS_slope, l_feat)
x.test <- model.matrix(l_feat$ALSFRS_slope~.,l_feat)[,-1]
y.test <- l_feat$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
ALSFRS_slope <- rep(0, dim(v_feat)[1])
v_feat <- data.frame(ALSFRS_slope, v_feat)
x.test <- model.matrix(v_feat$ALSFRS_slope~.,v_feat)[,-1]
y.test <- v_feat$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
mean((lasso.pred - validation.features)^2)
dim(lasso.pred)
dim(validation.features)
mean((lasso.pred - validation.target)^2)
avg <- mean(validation.target)
class(validation.target)
View(validation.target)
mean(validation.target$ALSFRS_slope)
ALSFRS_slope <- rep(0, dim(v_feat)[1])
v_feat <- data.frame(v_feat)
x.test <- model.matrix(v_feat$ALSFRS_slope~.,v_feat)[,-1]
y.test <- v_feat$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
ALSFRS_slope <- rep(0, dim(v_feat)[1])
v_feat <- data.frame(v_feat)
x.test <- model.matrix(v_feat)[,-1]
y.test <- v_feat$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
mean((lasso.pred - validation.target$ALSFRS_slope)^2)
mean((mean(validation.target$ALSFRS_slope) - validation.target$ALSFRS_slope)^2)
?merge.data.frame
df <- merge(t_feat, v_feat)
df <- merge(t_feat, v_feat, by = intersect(names(t_feat), names_v_feat))
df <- merge(t_feat, v_feat, by = intersect(names(t_feat), names(v_feat)))
View(t_feat)
v_feat <- v_feat[,!v_feat$ALSFRS_slope]
View(v_feat)
v_feat <- v_feat[,-1]
View(v_feat)
df <- merge(t_feat, v_feat)
dim(t_feat)
dim(v_feat)
dim(df)
df <- rbind(t_feat, v_feat)
dim(df)
dim(v_feat)
dim(t_feat)
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(l_feat, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- t_feat[,!col.has.na]
v_feat <- v_feat[,!col.has.na]
l_feat <- l_feat[,!col.has.na]
#lets merge t_feat and v_feat for training
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
train.frame <- data.frame(train.target, train.predictors)
View(train.frame)
View(training.target)
#massage data for the use of glmnet (needs matrix)
x = model.matrix(ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization (alpha=1)
grid = 10^seq(10,-2, length=100)
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
#perform cross validation on best choice of lambda
set.seed(1)
cv.out <- cv.glmnet(x,y,alpha=1)
plot(cv.out) # this takes about 3 minutes
bestlam <- cv.out$lambda.min
lasso.mod <- glmnet(x , y, alpha=1, lambda = bestlam)
ALSFRS_slope <- rep(0, dim(v_feat)[1])
temp <- data.frame(ALSFRS_slope, v_feat)
x.test <- model.matrix(temp$ALSFRS_slope~.,temp)[,-1]
y.test <- temp$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
dim(temp)
dim(train.frame)
train.frame <- train.frame[,-2]
View(train.frame)
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(l_feat, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- t_feat[,!col.has.na]
v_feat <- v_feat[,!col.has.na]
l_feat <- l_feat[,!col.has.na]
#lets merge t_feat and v_feat for training
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
train.frame <- data.frame(train.target[,2], train.predictors)
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(l_feat, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- t_feat[,!col.has.na]
v_feat <- v_feat[,!col.has.na]
l_feat <- l_feat[,!col.has.na]
#lets merge t_feat and v_feat for training
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
train.frame <- data.frame(train.target, train.predictors)
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(l_feat, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- t_feat[,!col.has.na]
v_feat <- v_feat[,!col.has.na]
l_feat <- l_feat[,!col.has.na]
#lets merge t_feat and v_feat for training
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
train.frame <- data.frame(train.target, train.predictors)
train.frame <- trainframe[,-train.frame$subject.id.1]
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(l_feat, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- t_feat[,!col.has.na]
v_feat <- v_feat[,!col.has.na]
l_feat <- l_feat[,!col.has.na]
#lets merge t_feat and v_feat for training
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
train.frame <- data.frame(train.target, train.predictors)
train.frame <- train.frame[,-train.frame$subject.id.1]
View(train.frame)
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(l_feat, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- t_feat[,!col.has.na]
v_feat <- v_feat[,!col.has.na]
l_feat <- l_feat[,!col.has.na]
#lets merge t_feat and v_feat for training
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
train.frame <- data.frame(train.target, train.predictors)
train.frame <- train.frame[,-3]
#massage data for the use of glmnet (needs matrix)
x = model.matrix(ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization (alpha=1)
grid = 10^seq(10,-2, length=100)
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
set.seed(1)
cv.out <- cv.glmnet(x,y,alpha=1)
# plot(cv.out) # this takes about 3 minutes
bestlam <- cv.out$lambda.min
ALSFRS_slope <- rep(0, dim(v_feat)[1])
temp.test <- data.frame(ALSFRS_slope, v_feat)
x.test <- model.matrix(temp.test$ALSFRS_slope~.,temp.test)[,-1]
y.test <- temp$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
avg <- mean(( mean(validation.target$ALSFRS_slope) - validation.target$ALSFRS_slope)^2)
avg
MSE <- mean(( validation.target$ALSFRS_slope - lasso.pred )^2)
MSE
ALSFRS_slope <- rep(0, dim(l_feat)[1])
temp.test <- data.frame(ALSFRS_slope, l_feat)
x.test <- model.matrix(temp.test$ALSFRS_slope~.,temp.test)[,-1]
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
ALSFRS_slope <- rep(0, dim(l_feat)[1])
temp.test <- data.frame(ALSFRS_slope, l_feat)
x.test <- model.matrix(temp.test$ALSFRS_slope~.,temp.test)[,-1]
# Perform predictions
leaderboard.lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
write.csv(leaderboard.lasso.pred, file = "../leaderboard_predictions.csv",row.names=FALSE)
ALSFRS_slope <- rep(0, dim(l_feat)[1])
temp.test <- data.frame(ALSFRS_slope, l_feat)
x.test <- model.matrix(temp.test$ALSFRS_slope~.,temp.test)[,-1]
# Perform predictions
leaderboard.lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
names(leaderboard.lasso.pred) = "ALSFRS_sloope"
# get into format for submission
leaderboard.predictions <- data.frame(leaderboard.features$subject.id, leaderboard.lasso.pred)
View(leaderboard.predictions)
ALSFRS_slope <- rep(0, dim(l_feat)[1])
temp.test <- data.frame(ALSFRS_slope, l_feat)
x.test <- model.matrix(temp.test$ALSFRS_slope~.,temp.test)[,-1]
# Perform predictions
leaderboard.lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
# get into format for submission
leaderboard.predictions <- data.frame(leaderboard.features$subject.id, leaderboard.lasso.pred)
names(leaderboard.predictions) = c("subject.id", "ALSFRS_slope")
View(leaderboard.predictions)
write.csv(leaderboard.predictions, file = "../leaderboard_predictions.csv",row.names=FALSE)
rm(list = ls())
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
# set NA's to medians for columns that have at least some data
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
l_feat <- as.data.frame(lapply(leaderboard.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
# find out which columns in v_feat are all NA, and remove these columns from t_feat, v_feat, l_feat
col.has.na <- apply(l_feat, 2, function(x){any(is.na(x))}) # logical of which columns are NA
t_feat <- t_feat[,!col.has.na]
v_feat <- v_feat[,!col.has.na]
l_feat <- l_feat[,!col.has.na]
# lets merge t_feat and v_feat for a training set
train.predictors <- rbind(t_feat, v_feat)
train.target <- rbind(training.target, validation.target)
train.frame <- data.frame(train.target, train.predictors)
train.frame <- train.frame[,-3] # subject id got copied in 2x, remove one of them
library(glmnet)
#massage data for the use of glmnet (needs matrix)
x = model.matrix(ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization (alpha=1)
grid = 10^seq(10,-2, length=1000)
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
set.seed(1)
cv.out <- cv.glmnet(x,y,alpha=1)
# plot(cv.out) # this takes about 3 minutes
bestlam <- cv.out$lambda.min
View(leaderboard.features)
ALSFRS_slope <- rep(0, dim(v_feat)[1])
temp.test <- data.frame(ALSFRS_slope, v_feat)
x.test <- model.matrix(temp.test$ALSFRS_slope~.,temp.test)[,-1]
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
avg <- mean(( mean(validation.target$ALSFRS_slope) - validation.target$ALSFRS_slope)^2)
avg
MSE <- mean(( validation.target$ALSFRS_slope - lasso.pred )^2)
MSE
ALSFRS_slope <- rep(0, dim(l_feat)[1])
temp.test <- data.frame(ALSFRS_slope, l_feat)
x.test <- model.matrix(temp.test$ALSFRS_slope~.,temp.test)[,-1]
# Perform predictions
leaderboard.lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
# get into format for submission
leaderboard.predictions <- data.frame(leaderboard.features$subject.id, leaderboard.lasso.pred)
names(leaderboard.predictions) = c("subject.id", "ALSFRS_slope")
write.csv(leaderboard.predictions, file = "../leaderboard_predictions.csv",row.names=FALSE)
install.packages("xgboost")
library(xgboost)
?xgboost
devtools::install_github('dmlc/xgboost', subdir='R-package')
install.packages("devtools")
devtools::install_github('dmlc/xgboost', subdir='R-package')
