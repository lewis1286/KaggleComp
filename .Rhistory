hist(var.12)
# boot.pca <- function(dataframe, index){
#   pca <- prcomp(dataframe[index,], scale = TRUE)
#   pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
#   return(sum(pca.var.explained[1:2]))
# }
# boot(USArrests, boot.pca, R=1000)
# not sure how to store the statistic, lets write out own bootstrapping function
n = 1000
k = dim(USArrests)[1]
var.12 <- rep(0,n)
for (i in seq(1,n) ) {
index <- sample(k, replace = TRUE)
pca <- prcomp(USArrests[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
var.12[i] <- sum(pca.var.explained[1:2])
}
hist(var.12)
# boot.pca <- function(dataframe, index){
#   pca <- prcomp(dataframe[index,], scale = TRUE)
#   pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
#   return(sum(pca.var.explained[1:2]))
# }
# boot(USArrests, boot.pca, R=1000)
# not sure how to store the statistic, lets write out own bootstrapping function
n = 1000
k = dim(USArrests)[1]
var.12 <- rep(0,n)
for (i in seq(1,n) ) {
index <- sample(k, replace = TRUE)
pca <- prcomp(USArrests[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
var.12[i] <- sum(pca.var.explained[1:2])
}
hist(var.12)
?xlab
??xlab
# boot.pca <- function(dataframe, index){
#   pca <- prcomp(dataframe[index,], scale = TRUE)
#   pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
#   return(sum(pca.var.explained[1:2]))
# }
# boot(USArrests, boot.pca, R=1000)
# not sure how to store the statistic, lets write out own bootstrapping function
n = 1000
k = dim(USArrests)[1]
var.12 <- rep(0,n)
for (i in seq(1,n) ) {
index <- sample(k, replace = TRUE)
pca <- prcomp(USArrests[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
var.12[i] <- sum(pca.var.explained[1:2])
}
hist(var.12, xlab("%Var(1) + %Var(2)"), ylab("count"), title("PCA percent of variance explained in first two components"))
?hist
# boot.pca <- function(dataframe, index){
#   pca <- prcomp(dataframe[index,], scale = TRUE)
#   pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
#   return(sum(pca.var.explained[1:2]))
# }
# boot(USArrests, boot.pca, R=1000)
# not sure how to store the statistic, lets write out own bootstrapping function
n = 1000
k = dim(USArrests)[1]
var.12 <- rep(0,n)
for (i in seq(1,n) ) {
index <- sample(k, replace = TRUE)
pca <- prcomp(USArrests[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
var.12[i] <- sum(pca.var.explained[1:2])
}
hist(var.12, xlab ="%Var(1) + %Var(2)" , ylab("count"), title("PCA percent of variance explained in first two components"))
# boot.pca <- function(dataframe, index){
#   pca <- prcomp(dataframe[index,], scale = TRUE)
#   pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
#   return(sum(pca.var.explained[1:2]))
# }
# boot(USArrests, boot.pca, R=1000)
# not sure how to store the statistic, lets write out own bootstrapping function
n = 1000
k = dim(USArrests)[1]
var.12 <- rep(0,n)
for (i in seq(1,n) ) {
index <- sample(k, replace = TRUE)
pca <- prcomp(USArrests[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
var.12[i] <- sum(pca.var.explained[1:2])
}
hist(var.12, xlab ="%Var(1) + %Var(2)" , ylab ="count" , title("PCA percent of variance explained in first two components"))
# boot.pca <- function(dataframe, index){
#   pca <- prcomp(dataframe[index,], scale = TRUE)
#   pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
#   return(sum(pca.var.explained[1:2]))
# }
# boot(USArrests, boot.pca, R=1000)
# not sure how to store the statistic, lets write out own bootstrapping function
n = 1000
k = dim(USArrests)[1]
var.12 <- rep(0,n)
for (i in seq(1,n) ) {
index <- sample(k, replace = TRUE)
pca <- prcomp(USArrests[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
var.12[i] <- sum(pca.var.explained[1:2])
}
hist(var.12, xlab ="%Var(1) + %Var(2)" , ylab ="count" , title("PCA comp. 1,2 variance"))
# boot.pca <- function(dataframe, index){
#   pca <- prcomp(dataframe[index,], scale = TRUE)
#   pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
#   return(sum(pca.var.explained[1:2]))
# }
# boot(USArrests, boot.pca, R=1000)
# not sure how to store the statistic, lets write out own bootstrapping function
n = 1000
k = dim(USArrests)[1]
var.12 <- rep(0,n)
for (i in seq(1,n) ) {
index <- sample(k, replace = TRUE)
pca <- prcomp(USArrests[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
var.12[i] <- sum(pca.var.explained[1:2])
}
hist(var.12, xlab ="%Var(1) + %Var(2)" , ylab ="count" , title ="PCA comp. 1,2 variance" )
# boot.pca <- function(dataframe, index){
#   pca <- prcomp(dataframe[index,], scale = TRUE)
#   pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
#   return(sum(pca.var.explained[1:2]))
# }
# boot(USArrests, boot.pca, R=1000)
# not sure how to store the statistic, lets write out own bootstrapping function
n = 1000
k = dim(USArrests)[1]
var.12 <- rep(0,n)
for (i in seq(1,n) ) {
index <- sample(k, replace = TRUE)
pca <- prcomp(USArrests[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
var.12[i] <- sum(pca.var.explained[1:2])
}
hist(var.12, xlab ="%Var(1) + %Var(2)" , ylab ="count" , main =paste("PCA comp. 1,2 variance") )
#get standard error from bootstrapping function
boot.pca <- function(dataframe, index){
pca <- prcomp(dataframe[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
return(sum(pca.var.explained[1:2]))
}
boot(USArrests, boot.pca, R = 1000)
#get standard error from bootstrapping function
boot.pca <- function(dataframe, index){
pca <- prcomp(dataframe[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
return(sum(pca.var.explained[1:2]))
}
boot(USArrests, boot.pca, R = 1000)[3]
#get standard error from bootstrapping function
boot.pca <- function(dataframe, index){
pca <- prcomp(dataframe[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
return(sum(pca.var.explained[1:2]))
}
boot(USArrests, boot.pca, R = 1000)[3]
hist(boot$t[,1])
#get standard error from bootstrapping function
boot.pca <- function(dataframe, index){
pca <- prcomp(dataframe[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
return(sum(pca.var.explained[1:2]))
}
b <- boot(USArrests, boot.pca, R = 1000)[3]
hist(b$t[,1])
b
b$R
#get standard error from bootstrapping function
boot.pca <- function(dataframe, index){
pca <- prcomp(dataframe[index,], scale = TRUE)
pca.var.explained <- (pca$sdev^2 ) / sum(pca$sdev^2)
return(sum(pca.var.explained[1:2]))
}
b <- boot(USArrests, boot.pca, R = 1000)
hist(b$t[,1])
?boot
b
mean(b$t[,8]^2)
head(b$t)
dim(b$t0)
dim(b$t)
b$statistic()
b$t0
sqrt(sum((b$t[,1]-b$t0)^2))
b[2]
b[1]
b[3]
b[4]
b[5]
b[6]
b[7]
b[8]
b[9]
b[10]
b[11]
b[12]
b[13]
b[14]
b
b$t0
b
SE <- .02153514
conf.95 <- c(b$t0 - 2*SE, b$t0 + 2*SE )
conf.95
boot.se = .3934978
boot.conf = c(medv.mu.est - 2*boot.se, medv.mu.est + 2*boot.se)
boot.conf
t.test(medv)
(boot.conf[2] - boot.conf[1])  /  (23.33608 - 21.72953)
b
SE <- .02153514
conf.95 <- c(b$t0 - 2*SE, b$t0 + 2*SE )
conf.95
?pccomp
prcomp
?prcomp
pca <- prcomp(USArrests)
pca
pca$rotation[PC1]
pca$rotation[,PC1]
pca$rotation[,1]
?which.max
which.max(pca$rotation[,1])
?boxplot
b
b$statistic()
b$t
var.loads = function(dataframe){
pca <- prcomp(dataframe)
max.load <- which.max(abs(pca$rotation[,1])) # index of direction of maximum loading
boot.loads <- function(dataframe, index){
pca <- prcomp(dataframe, subset = index)
sign <- pca$rotation[max.load, 1] / abs(pca$rotation[max.load, 1])
return(sign * pca$rotation[,1])
}
b <- boot(dataframe, boot.loads, R = 1000)
boxplot(b$t)
}
var.loads(USArrests)
rm(list=ls())
var.loads = function(dataframe){
pca <- prcomp(dataframe)
max.load <- which.max(abs(pca$rotation[,1])) # index of direction of maximum loading
boot.loads <- function(dataframe, index){
pca <- prcomp(dataframe, subset = index)
sign <- pca$rotation[max.load, 1] / abs(pca$rotation[max.load, 1])
return(sign * pca$rotation[,1])
}
b <- boot(dataframe, boot.loads, R = 1000)
boxplot(b$t)
}
var.loads(USArrests)
View(var.loads)
var.loads = function(dataframe){
pca <- prcomp(dataframe)
max.load <- which.max(abs(pca$rotation[,1])) # index of direction of maximum loading
boot.loads <- function(dataframe, index){
pca <- prcomp(dataframe, subset = index)
sign <- pca$rotation[max.load, 1] / abs(pca$rotation[max.load, 1])
return(sign * pca$rotation[,1])
}
b <- boot(dataframe, boot.loads, R = 1000)
boxplot(b$t)
return(b)
}
b <- var.loads(USArrests)
b$t0
b$t
prcomp(USArrests)
prcomp(USArrests, subset = seq(10))
dim(USArrests)
?prcomp
var.loads = function(dataframe){
pca <- prcomp(dataframe)
max.load <- which.max(abs(pca$rotation[,1])) # index of direction of maximum loading
boot.loads <- function(dataframe[index,]){
pca <- prcomp(dataframe, subset = index)
sign <- pca$rotation[max.load, 1] / abs(pca$rotation[max.load, 1])
return(sign * pca$rotation[,1])
}
b <- boot(dataframe, boot.loads, R = 20)
boxplot(b$t)
return(b)
}
b <- var.loads(USArrests)
var.loads = function(dataframe){
pca <- prcomp(dataframe)
max.load <- which.max(abs(pca$rotation[,1])) # index of direction of maximum loading
boot.loads <- function(dataframe, index){
pca <- prcomp(dataframe[index,])
sign <- pca$rotation[max.load, 1] / abs(pca$rotation[max.load, 1])
return(sign * pca$rotation[,1])
}
b <- boot(dataframe, boot.loads, R = 20)
boxplot(b$t)
return(b)
}
b <- var.loads(USArrests)
prcomp(USArrests)
?boxplot
names(USArrests)
var.loads = function(dataframe){
pca <- prcomp(dataframe)
max.load <- which.max(abs(pca$rotation[,1])) # index of direction of maximum loading
boot.loads <- function(dataframe, index){
pca <- prcomp(dataframe[index,])
sign <- pca$rotation[max.load, 1] / abs(pca$rotation[max.load, 1])
return(sign * pca$rotation[,1])
}
b <- boot(dataframe, boot.loads, R = 20)
boxplot(b$t, xlab="component", ylab = "loading", main=paste("PCA vector 1 loadings"), names = names(USArrests))
return(b)
}
b <- var.loads(USArrests)
?sample
rm(list=ls())
set.seed(1)
library(ISLR)
library(boot)
attach(Default)
glm.fit <- glm( formula = default ~ balance + income, data = Default, family=binomial)
summary(glm.fit)
summary(glm.fit)$coefficients
summary(glm.fit)$coefficients[2:3,]
summary(glm.fit)$coefficients[2:3,2]
#boot.fn(dataframe, index)  (adapted from ISLR pp 195)
#inputs: dataframe, and vector of indexes of observations of interest (a subset)
#output: coefficient estimates for 'income', 'balance' found by multiple logistic regression
boot.fn <- function(dataframe, index){
return(coef(glm(default ~ balance + income, data = dataframe,
family = binomial, subset = index))[2:3])
}
boot(Default, boot.fn, R=1000) #boot sticks arguments into boot.fn()
boot(Default, boot.fn, R=100) #boot sticks arguments into boot.fn()
set.seed(1)
x=rnorm(100)
y = x - 2*x^2 + rnorm(100)
plot(x,y)
training_target_mean <- mean(training.target$ALSFRS_slope)
print(training_target_mean)
leaderboard.predictions$ALSFRS_slope <- training_target_mean
rm(list=ls())
# Change this to your data directory
data.dir <- "~/Dropbox/classes/STATs 202 data mining and analysis/ALS-kaggle-comp/KaggleComp/"
setwd(data.dir)
# Read in each data files into a data frame
training.target <- read.csv("../training_target.csv")
training.features <- read.csv("../training_features.csv")
validation.features <- read.csv("../validation_features.csv")
validation.target <- read.csv("../validation_target.csv")
leaderboard.features<- read.csv("../leaderboard_features.csv")
head(training.target)
leaderboard.predictions <- read.csv("../leaderboard_predictions-example.csv")
head(leaderboard.predictions)
training_target_mean <- mean(training.target$ALSFRS_slope)
print(training_target_mean)
leaderboard.predictions$ALSFRS_slope <- training_target_mean
write.csv(leaderboard.predictions, file = "leaderboard_predictions-training_mean.csv",row.names=FALSE)
write.csv(leaderboard.predictions, file = "../leaderboard_predictions-training_mean.csv",row.names=FALSE)
t_feat <- as.data.frame(lapply(t_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
head(training.features)
head(training.target)
training.features[1:6,1:3]
train.frame <- data.frame(training.target[,2], t_feat)
x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
t_feat <- as.data.frame(lapply(training_features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
train.frame <- data.frame(training.target[,2], t_feat)
x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
train.frame[1:4,1:4]
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
train.frame[1:4,1:4]
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
head(training.target)
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
names(train.frame$training.target.ALSFRS_slope) <- ALSFRS_slope
x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
train.frame[1:3,1:3]
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
names(train.frame$training.target.ALSFRS_slope) <- "ALSFRS_slope"
train.frame[1:3,1:3]
# x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
names(train.frame$training.target.ALSFRS_slope) <- c("ALSFRS_slope")
train.frame[1:3,1:3]
# x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
colnames(train.frame)[1] <- "ALSFRS_slope"
train.frame[1:3,1:3]
# x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
colnames(train.frame)[1] <- "ALSFRS_slope"
# train.frame[1:3,1:3]
x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
library(glmnet)
install.packages("glmnet")
library(glmnet)
#massage data for the use of glmnet (needs matrix)
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
colnames(train.frame)[1] <- "ALSFRS_slope"
# train.frame[1:3,1:3]
x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
plot(lasso.mod)
library(glmnet)
#massage data for the use of glmnet (needs matrix)
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
colnames(train.frame)[1] <- "ALSFRS_slope"
# train.frame[1:3,1:3]
x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
plot(lasso.mod)
#massage data for the use of glmnet (needs matrix)
train.frame <- data.frame(training.target$ALSFRS_slope, t_feat)
colnames(train.frame)[1] <- "ALSFRS_slope"
# train.frame[1:3,1:3]
x = model.matrix(train.frame$ALSFRS_slope~., train.frame)[,-1]
y = train.frame$ALSFRS_slope
#perform lasso regularization
grid = 10^seq(10,-2, length=100)
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
plot(lasso.mod)
grid
plot(lasso.mod)
dim(coef(lasso.mod))
coef(lasso.mod)[1,1:6]
coef(lasso.mod)[1:6,1:6]
View(train.frame)
sum(is.na(train.frame$ALSFRS_slope))
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
n <- as.vector(lapply(train.frame, function(x) {sum(is.na(x)); x }))
summary(n)
n <- as.vector(lapply(train.frame, function(x) {ifelse(sum(is.na(x)) == 0, 0, 1); x }))
summary(n)
lapply(train.frame, function(x) {ifelse(sum(is.na(x)) == 0, 0, 1); x }))
lapply(train.frame, function(x) {ifelse(sum(is.na(x)) == 0, 0, 1); x })
library(ISLR)
fix(Hitters)
Hitters=na.omit(Hitters)
dim(train.frame)
df <- na.omit(train.frame)
dim(df)
fix(Hitters)
dim(Hitters)
sum(is.na(training.features))
sum(is.na(training.target))
sum(is.na(train.frame))
ridge.mod <- glmnet(x,y,alpha=0,lambda=grid)
dim(coef(ridge.mod))
coef(ridge.mod)[1:5,1:5]
lasso.mod <- glmnet(x , y, alpha=1, lambda = grid)
coef(lasso.mod)[1:5,1:5]
dim(coef(lasso.mod))
sum(is.na(lasso.mod))
sum(coef(lasso.mod)[,1])
sum(coef(lasso.mod)[,50])
sum(coef(lasso.mod)[,98])
coef(lasso.mod)[1:20,95:100]
#perform cross validation
set.seed(1)
cv.out <- cv.glmnet(x,y,alpha=1)
plot(cv.out)
bestlam <- cv.out$lambda.min
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
View(validation.target)
bestlam <- cv.out$lambda.min
# build a test matrix to predict on:
test.frame <- data.frame(validation.target$ALSFRS_slope, v_feat)
colnames(test.frame)[1] <- "ALSFRS_slope"
x.test = model.matrix(ALSFRS_slope~., test.frame)[,-1]
y.test = test.frame$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
test.frame[1:4,1:4]
x.test = model.matrix(ALSFRS_slope~., test.frame)[,-1]
View(x.test)
x.test = model.matrix(ALSFRS_slope~., test.frame)
x.test = model.matrix(ALSFRS_slope~., test.frame)[,-1]
dim(x.test)
dim(test.frame)
sum(is.na(test.frame))
t_feat <- as.data.frame(lapply(training.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
v_feat <- as.data.frame(lapply(validation.features, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
sum(is.na(test.frame))
bestlam <- cv.out$lambda.min
# build a test matrix to predict on:
test.frame <- data.frame(validation.target$ALSFRS_slope, v_feat)
colnames(test.frame)[1] <- "ALSFRS_slope"
x.test = model.matrix(ALSFRS_slope~., test.frame)[,-1]
y.test = test.frame$ALSFRS_slope
# Perform predictions
lasso.pred <- predict(lasso.mod, s=bestlam, newx = x.test)
sum(is.na(test.frame))
sum(is.na(v_feat))
sum(is.na(validatio.features))
sum(is.na(validation.features))
sum(is.na(v_feat))
sum(is.na(t_feat))
v_feat <- as.data.frame(lapply(v_feat, function(x) {x[is.na(x)] <- median(x, na.rm=TRUE); x}))
sum(is.na(v_feat))
